\section{Dataset}
To build a reliable image recognition system that can help identify the number of students, having a high-quality and comprehensive database is of paramount importance. The dataset serves as the foundational resource for training and testing the image recognition system, and its quantity, quality, and diversity are all crucial factors. Constructing a high-quality dataset primarily relies on several key steps, each of which plays a critical role in training and developing an accurate and reliable image recognition system. These steps include data collection, data annotation, data preprocessing, and dataset partitioning for evaluation and deployment.\\
\label{sec:method}
\subsection{Data Collection}
\label{subsec:method}
To ensure we have enough data, we've collected information from various sources. Initially, we started by acquiring a portion of publicly available data online, specifically leveraging the \href{https://cocodataset.org/#home}{\underline{Microsoft COCO(COCO Dataset))}}. This dataset contains a wide array of images featuring individuals from various backgrounds, orientations, ethnicities, and settings. In our dataset, we've incorporated a subset of this COCO data, which adds diversity and improves the accuracy of our image recognition system. Beyond these open-source databases, our dataset also incorporates data from other origins. For instance, in each class section, we've taken a set of photographs from different angles with the consent of our classmates. These photos hold significant importance for the practical application of our system, as they closely mirror the real-world environment where our recognition system will be put into use. To further enrich our dataset's diversity, we've collaborated with other teams working on similar projects and obtained a portion of shared data.\\
\label{sec:method}
\subsection{Data Labeling}
\label{subsec:method}
To achieve clearer identification of objects within images, especially the target subjects, each image in our dataset needs to be carefully outlined and annotated. These labels effectively specify the position and identity of each object to be recognized within the images. Annotating individual objects can be accomplished through manual annotation, where humans identify and mark the regions of individuals in the pictures, or through other tools designed for object recognition and annotation. The data obtained from the COCO dataset also comes with precise annotations. To enhance the accuracy of image recognition, we require a substantial amount of labeled data to train our image recognition system. The accuracy of labeling directly impacts the reliability of our system, making accurate annotation the foundation of our system.\\
\label{sec:method}
\subsection{Data Preprocessing}
\label{subsec:method}
Thoroughly cleaning and preparing the data is another crucial part of creating our dataset. This step is essential to make sure that all the images in our dataset have consistent quality and can be effectively used for both training and testing our system. During this phase, we carry out various tasks on the data, including data we obtained from the COCO dataset and our own captured data. In this stage, we do things like resizing images to a uniform size, reducing any noise in the pictures, standardizing the brightness and contrast in the images, and aligning facial features to improve accuracy. Data preprocessing not only improves the overall quality of our dataset but also makes the training process smoother by providing the model with standardized inputs. This standardization is crucial to ensure that our image recognition system can perform well under different lighting conditions, facial expressions, and variations in image quality, allowing it to work effectively in various real-world situations.\\
\label{sec:method}
\subsection{Data Partitioning}
\label{subsec:method}
After going through the previous steps, the final critical step in dataset construction involves dividing the dataset into different subsets. These subsets typically include a training set, a validation set, and a test set. The training set is used to train our image recognition system, allowing it to learn the patterns and features of individuals in images. The validation set is used to fine-tune the model's parameters and implement early stopping techniques to prevent overfitting. The test set is used to evaluate the overall performance of the trained model, providing a fair assessment of its accuracy and robustness. Currently, we have around 4,000 training data samples, over 700 validation data samples, and approximately 70 test data samples. Since the COCO dataset provides a substantial amount of suitable data, we included a portion of it in our training set. In the validation set, we incorporated data obtained from other collaborating teams to fine-tune the model. Finally, for the test set, we used data from our daily attendance photos to validate the reliability of our system in a real-world attendance environment.\\
