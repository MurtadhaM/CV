\section{Dataset}
The first step to building an image recognition system that will help identify the number of students, we need to start by having a high-quality set of images. The dataset serves as the foundation for training and testing the image recognition system, and the quantity, quality, and diversity of the images in this dataset are all also factors that affect it's performance. Constructing a high-quality dataset primarily includes data collection, data annotation, data preprocessing, and dataset partitioning for evaluation and deployment.\\
\label{sec:method}
\subsection{Data Collection}
\label{subsec:method}
To ensure we have enough data, we've collected information from various sources. Initially, we started by acquiring a portion of publicly available data online, specifically leveraging the \href{https://cocodataset.org/#home}{\underline{Microsoft COCO(COCO Dataset))}} [3]. This dataset contains a wide array of images featuring individuals from various backgrounds, orientations, ethnicities, and settings. We used this specific dataset because it is quite well-knnown and has numerous sections which are applicable to our specific use-case such as the person classier. Beyond that open-source database, our validation images also incorporate our individual student experiences. For instance, in each class that we are in, we've taken a set of photographs from different angles with the consent of our classmates. These photos hold significant importance for the practical application of our system, as they closely mirror the real-world environment (classrooms) where our recognition system will be put into use. To further enrich our dataset's diversity, we've collaborated with other teams working on similar projects and obtained a portion of shared data.\\
\label{sec:method}
\subsection{Data Labeling}
\label{subsec:method}
To achieve clearer identification of objects within images, especially the target subjects, each image in our dataset needs to be carefully outlined and annotated. These labels effectively specify the position and identity of each object to be recognized within the images. Annotating individual objects can be accomplished through manual annotation, where humans identify and mark the regions of individuals in the pictures, or through other tools designed for object recognition and annotation. The data obtained from the COCO dataset also comes with precise annotations. To enhance the accuracy of image recognition, we require a substantial amount of labeled data to train our image recognition system. The accuracy of labeling directly impacts the reliability of our system, making accurate annotation the foundation of our system.\\
\label{sec:method}
\subsection{Data Preprocessing}
\label{subsec:method}
Thoroughly preparing the data is another part of preparing our dataset. This step is essential to make sure that all the images in our dataset have consistent quality and can be effectively used for both training and testing our system. During this phase, we carry out various tasks on the data, including data we obtained from the COCO dataset and our own captured data. In this stage, we resized images to a uniform size, removed noise, standardized the brightness and contrast in the images, and aligned facial features to improve accuracy. Preprocessing the data not only improved the overall quality of our dataset but also made the training process smoother by providing the model with standardized inputs. This standardization is to ensure that our image recognition system can perform well under different lighting conditions, facial expressions, and variations in image quality.\\
\label{sec:method}
\subsection{Data Partitioning}
\label{subsec:method}
After going through the previous steps, the final critical step in dataset construction involves dividing the dataset into different subsets. These subsets typically include a training set, a validation set, and a test set. The training set is used to train our image recognition system, allowing it to learn the patterns and features of individuals in images. The validation set is used to fine-tune the model's parameters and implement early stopping techniques to prevent overfitting. The test set is used to evaluate the overall performance of the trained model, providing a fair assessment of its accuracy and robustness. Currently, we have around 4,000 training data samples, over 700 validation data samples, and approximately 70 test data samples. Since the COCO dataset provides a substantial amount of suitable data, we included a portion of it in our training set. In the validation set, we incorporated data obtained from other collaborating teams to fine-tune the model. Finally, for the test set, we used data from our daily attendance photos to validate the reliability of our system in a real-world attendance environment.\\
